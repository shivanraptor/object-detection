{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (20.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.33.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.35.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.23.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2020.11.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow --use-feature=2020-resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 04:16:52,970\tINFO worker.py:946 -- Connecting to existing Ray cluster at address: 172.24.31.101:6379\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-bc00985d06dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gpu_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/ray/worker.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(address, num_cpus, num_gpus, resources, object_store_memory, local_mode, ignore_reinit_error, include_dashboard, dashboard_host, dashboard_port, job_config, configure_logging, logging_level, logging_format, log_to_driver, namespace, runtime_env, storage, _enable_object_reconstruction, _redis_max_memory, _plasma_directory, _node_ip_address, _driver_object_store_memory, _memory, _redis_password, _temp_dir, _metrics_export_port, _system_config, _tracing_startup_hook, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mRayContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_global_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddress_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    968\u001b[0m                 \u001b[0;34m\"Maybe you called ray.init twice by accident? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 \u001b[0;34m\"This error can be suppressed by passing in \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Maybe you called ray.init twice by accident? This error can be suppressed by passing in 'ignore_reinit_error=True' or by calling 'ray.shutdown()' prior to 'ray.init()'."
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(address=\"auto\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'NodeID': '5671f6d6e692cc0aa29ef688b5494d2f6cb7b5d56cdebbefaaba42ac',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '172.24.31.101',\n",
       "  'NodeManagerHostname': 'mgmt01',\n",
       "  'NodeManagerPort': 39889,\n",
       "  'ObjectManagerPort': 37609,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-06-02_02-37-25_924604_37/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-06-02_02-37-25_924604_37/sockets/raylet',\n",
       "  'MetricsExportPort': 56458,\n",
       "  'alive': True,\n",
       "  'Resources': {'object_store_memory': 4895835340.0,\n",
       "   'CPU': 4.0,\n",
       "   'memory': 9791670683.0,\n",
       "   'node:172.24.31.101': 1.0}},\n",
       " {'NodeID': '59496ae8c13baa067dd4e28bc95cdd1fe531e2314f7f0c5231ea94d2',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '172.24.31.103',\n",
       "  'NodeManagerHostname': 'gpu02',\n",
       "  'NodeManagerPort': 36761,\n",
       "  'ObjectManagerPort': 41267,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-06-02_02-37-25_924604_37/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-06-02_02-37-25_924604_37/sockets/raylet',\n",
       "  'MetricsExportPort': 56304,\n",
       "  'alive': True,\n",
       "  'Resources': {'object_store_memory': 40412123136.0,\n",
       "   'memory': 94294953984.0,\n",
       "   'node:172.24.31.103': 1.0,\n",
       "   'CPU': 40.0,\n",
       "   'GPU': 4.0,\n",
       "   'accelerator_type:G': 1.0}},\n",
       " {'NodeID': 'fbef77931bc3a5d75b862691ad52f504ae2676638a1f1fadc5125e4f',\n",
       "  'Alive': True,\n",
       "  'NodeManagerAddress': '172.24.31.105',\n",
       "  'NodeManagerHostname': 'gpu01',\n",
       "  'NodeManagerPort': 38411,\n",
       "  'ObjectManagerPort': 44091,\n",
       "  'ObjectStoreSocketName': '/tmp/ray/session_2022-06-02_02-37-25_924604_37/sockets/plasma_store',\n",
       "  'RayletSocketName': '/tmp/ray/session_2022-06-02_02-37-25_924604_37/sockets/raylet',\n",
       "  'MetricsExportPort': 60411,\n",
       "  'alive': True,\n",
       "  'Resources': {'memory': 94291263898.0,\n",
       "   'CPU': 40.0,\n",
       "   'node:172.24.31.105': 1.0,\n",
       "   'object_store_memory': 40410541670.0,\n",
       "   'accelerator_type:G': 1.0,\n",
       "   'GPU': 4.0}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 1: Initializing TensorFlow\n",
      "Stage 1 completed in 3.21 seconds\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Validating Tensorflow version\n",
    "# =============================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 1: Initializing TensorFlow\")\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 1 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 2: Importing common libraries\n",
      "Stage 2 completed in 0.19 seconds\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Importing common libraries\n",
    "# ==========================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 2: Importing common libraries\")\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # suppress AVX2 FMA not supported error\n",
    "import urllib\n",
    "import tarfile\n",
    "import numpy as np\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 2 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============\n",
    "# Helper Codes\n",
    "# ============\n",
    "# Font to draw text on image\n",
    "FONT_NAME = 'Chalkduster.ttf'\n",
    "\n",
    "# Bounding box colors\n",
    "COLORS = ['Green',\n",
    "          'Red', 'Pink',\n",
    "          'Olive', 'Brown', 'Gray',\n",
    "          'Cyan', 'Orange']\n",
    "\n",
    "class ObjectResult:\n",
    "    \"\"\"\n",
    "    Represents a detection result, containing the object label,\n",
    "    score confidence, and bounding box coordinates.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, label, score, box):\n",
    "        self.label = label\n",
    "        self.score = score\n",
    "        self.box = box\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{0} ({1}%)'.format(self.label, int(100 * self.score))\n",
    "\n",
    "\n",
    "N_CHANNELS = 3\n",
    "\n",
    "def load_image_into_numpy_array(image):\n",
    "    \"\"\"\n",
    "    Converts a PIL image into a numpy array (height x width x channels).\n",
    "    :param image: PIL image\n",
    "    :return: numpy array\n",
    "    \"\"\"\n",
    "    (width, height) = image.size\n",
    "    return np.array(image.getdata()) \\\n",
    "        .reshape((height, width, N_CHANNELS)).astype(np.uint8)\n",
    "\n",
    "def process_output(classes, scores, boxes, category_index):\n",
    "    \"\"\"\n",
    "    Processes classes, scores, and boxes, gathering in a list of ObjectResult.\n",
    "    :param classes: list of class id\n",
    "    :param scores: list of scores\n",
    "    :param boxes: list of boxes\n",
    "    :param category_index: label dictionary\n",
    "    :return: list of ObjectResult\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for clazz, score, box in zip(classes, scores, boxes):\n",
    "        if score > 0.0:\n",
    "            label = category_index[clazz][NAME_KEY]\n",
    "            obj_result = ObjectResult(label, score, box)\n",
    "            results.append(obj_result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "import random\n",
    "import PIL.Image as Image\n",
    "\n",
    "def draw_labeled_boxes(image_np, results, min_score=.4):\n",
    "    \"\"\"\n",
    "    Draws labeled boxes according to results on the given image.\n",
    "    :param image_np: numpy array image\n",
    "    :param results: list of ObjectResult\n",
    "    :param min_score: optional min score threshold, default is 40%\n",
    "    :return: numpy array image with labeled boxes drawn\n",
    "    \"\"\"\n",
    "    results.sort(key=lambda x: x.score, reverse=False)\n",
    "    image_np_copy = image_np.copy()\n",
    "    for r in results:\n",
    "        if r.score >= min_score:\n",
    "            color_idx = random.randint(0, len(COLORS) - 1)\n",
    "            color = COLORS[color_idx]\n",
    "\n",
    "            image_pil = Image.fromarray(np.uint8(image_np_copy)).convert('RGB')\n",
    "            draw_bounding_box_on_image(image_pil, r.box, color, str(r))\n",
    "            np.copyto(image_np_copy, np.array(image_pil))\n",
    "\n",
    "    return image_np_copy\n",
    "\n",
    "import PIL.ImageFont as ImageFont\n",
    "\n",
    "def get_suitable_font_for_text(text, img_width, font_name, img_fraction=0.12):\n",
    "    \"\"\"\n",
    "    Calculates a suitable font for the image given the text and fraction.\n",
    "    :param text: text that will be drawn\n",
    "    :param img_width: width of the image\n",
    "    :param font_name: name of the font\n",
    "    :param img_fraction: optional desired image fraction allowed for the text \n",
    "    :return: suitable font\n",
    "    \"\"\"\n",
    "    fontsize = 1\n",
    "    font = ImageFont.truetype(FONT_NAME, fontsize)\n",
    "    while font.getsize(text)[0] < img_fraction*img_width:\n",
    "        fontsize += 1\n",
    "        font = ImageFont.truetype(font_name, fontsize)\n",
    "    return font\n",
    "\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "\n",
    "TEXT_COLOR = 'Black'\n",
    "\n",
    "def draw_bounding_box_on_image(image, box, color, box_label):\n",
    "    \"\"\"\n",
    "    Draws the box and label on the given image.\n",
    "    :param image: PIL image\n",
    "    :param box: numpy array containing the bounding box information\n",
    "                [top, left, bottom, right]\n",
    "    :param color: bounding box color\n",
    "    :param box_label: bounding box label\n",
    "    \"\"\"\n",
    "    im_width, im_height = image.size\n",
    "    top, left, bottom, right = box\n",
    "\n",
    "    # Normalize coordinates\n",
    "    left = left * im_width\n",
    "    right = right * im_width\n",
    "    top = top * im_height\n",
    "    bottom = bottom * im_height\n",
    "\n",
    "    # Draw the detected bounding box\n",
    "    line_width = int(max(im_width, im_height) * 0.005)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    draw.rectangle(((left, top), (right, bottom)),\n",
    "                   width=line_width,\n",
    "                   outline=color)\n",
    "\n",
    "    # Get a suitable font (in terms of size with respect to the image)\n",
    "    font = get_suitable_font_for_text(box_label, im_width, FONT_NAME)\n",
    "    text_width, text_height = font.getsize(box_label)\n",
    "\n",
    "    # Draw the box label rectangle\n",
    "    text_bottom = top + text_height\n",
    "    text_rect = ((left, top),\n",
    "                 (left + text_width + 2 * line_width,\n",
    "                  text_bottom + 2 * line_width))\n",
    "    draw.rectangle(text_rect, fill=color)\n",
    "\n",
    "    # Draw the box label text \n",
    "    # right below the upper-left horizontal line of the bounding box\n",
    "    text_position = (left + line_width, top + line_width)\n",
    "    draw.text(text_position, box_label, fill=TEXT_COLOR, font=font)\n",
    "\n",
    "# Input tensor\n",
    "IMAGE_TENSOR_KEY = 'image_tensor'\n",
    "\n",
    "# Output tensors\n",
    "DETECTION_BOXES_KEY = 'detection_boxes'\n",
    "DETECTION_SCORES_KEY = 'detection_scores'\n",
    "DETECTION_CLASSES_KEY = 'detection_classes'\n",
    "\n",
    "TENSOR_SUFFIX = ':0'\n",
    "\n",
    "def run_inference(graph, image_np):\n",
    "    \"\"\"\n",
    "    Runs the inference on the given image.\n",
    "    :param graph: tensorflow graph\n",
    "    :param image_np: numpy image\n",
    "    :return: dictionary with detected classes \n",
    "             and their corresponding scores and boxes\n",
    "    \"\"\"\n",
    "    output_tensor_dict = {\n",
    "        DETECTION_BOXES_KEY: DETECTION_BOXES_KEY + TENSOR_SUFFIX,\n",
    "        DETECTION_SCORES_KEY: DETECTION_SCORES_KEY + TENSOR_SUFFIX,\n",
    "        DETECTION_CLASSES_KEY: DETECTION_CLASSES_KEY + TENSOR_SUFFIX\n",
    "    }\n",
    "\n",
    "    with graph.as_default():\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            input_tensor = tf.compat.v1.get_default_graph()\\\n",
    "                .get_tensor_by_name(IMAGE_TENSOR_KEY + TENSOR_SUFFIX)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            input_tensor_dict = {input_tensor: image_np_expanded}\n",
    "            output_dict = sess.run(output_tensor_dict,\n",
    "                                   feed_dict=input_tensor_dict)\n",
    "\n",
    "            return {\n",
    "                DETECTION_BOXES_KEY: \n",
    "                    output_dict[DETECTION_BOXES_KEY][0],\n",
    "                DETECTION_SCORES_KEY: \n",
    "                    output_dict[DETECTION_SCORES_KEY][0],\n",
    "                DETECTION_CLASSES_KEY: \n",
    "                    output_dict[DETECTION_CLASSES_KEY][0].astype(np.int64)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 3: Getting the model file\n",
      "Stage 3 completed in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# ======================\n",
    "# Getting the model file\n",
    "# ======================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 3: Getting the model file\")\n",
    "MODEL_DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous_oid_v4_2018_12_12'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "\n",
    "if os.path.exists(MODEL_FILE) is False:\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(MODEL_DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 3 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 4: Getting the box description file\n",
      "Stage 4 completed in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# Getting the box description file\n",
    "# ================================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 4: Getting the box description file\")\n",
    "BOX_DESCRIPTIONS_FILE = 'class-descriptions-boxable.csv'\n",
    "OID_DOWNLOAD_BASE = 'https://storage.googleapis.com/openimages/2018_04/'\n",
    "\n",
    "if os.path.exists(BOX_DESCRIPTIONS_FILE) is False:\n",
    "    opener = urllib.request.URLopener()\n",
    "    opener.retrieve(OID_DOWNLOAD_BASE + BOX_DESCRIPTIONS_FILE, BOX_DESCRIPTIONS_FILE)\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 4 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 5: Getting test images\n",
      "Stage 5 completed in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# ===================\n",
    "# Getting test images\n",
    "# ===================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 5: Getting test images\")\n",
    "import glob\n",
    "\n",
    "def listdir_nohidden(path):\n",
    "    return glob.glob(os.path.join(path, '*'))\n",
    "\n",
    "TEST_IMAGES = []\n",
    "FOLDER_IMAGES = 'images/'\n",
    "IMG_FILTER = '*.jpg'\n",
    "if os.path.exists(FOLDER_IMAGES):\n",
    "    TEST_IMAGES = glob.glob(FOLDER_IMAGES + IMG_FILTER)\n",
    "else:\n",
    "\tprint(\"Folder not found\")\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 5 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 6: Extracting the model files\n",
      "Stage 6 completed in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# ==========================\n",
    "# Extracting the model files\n",
    "# ==========================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 6: Extracting the model files\")\n",
    "FROZEN_GRAPH_FILE = 'frozen_inference_graph.pb'\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(MODEL_NAME, FROZEN_GRAPH_FILE)\n",
    "\n",
    "if os.path.exists(MODEL_NAME) is False:\n",
    "    tar_file = tarfile.open(MODEL_FILE)\n",
    "    for file in tar_file.getmembers():\n",
    "        filename = os.path.basename(file.name)\n",
    "        if FROZEN_GRAPH_FILE in filename:\n",
    "            tar_file.extract(file, os.getcwd())\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 6 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Stage 7: Loading the box descriptions into a dictionary\n",
      "Stage 7 completed in 0.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# Loading the box descriptions into a dictionary\n",
    "# ==============================================\n",
    "tic = time.perf_counter()\n",
    "print(\"* Stage 7: Loading the box descriptions into a dictionary\")\n",
    "import pandas as pd\n",
    "\n",
    "ID_KEY = 'id'\n",
    "CLASS_KEY = 'class'\n",
    "NAME_KEY = 'name'\n",
    "\n",
    "df = pd.read_csv(BOX_DESCRIPTIONS_FILE, names=[ID_KEY, CLASS_KEY])\n",
    "category_index = {}\n",
    "for idx, row in df.iterrows():\n",
    "    category_index[idx+1] = {ID_KEY: row[ID_KEY], NAME_KEY: row[CLASS_KEY]}\n",
    "toc = time.perf_counter()\n",
    "print(\"Stage 7 completed in\", round(toc - tic, 2), \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(ca80f3a8e8ba2e50ffffffffffffffffffffffff0400000001000000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================\n",
    "# Loading the frozen model from file\n",
    "# ==================================\n",
    "tf.get_logger().setLevel('WARNING')\n",
    "\n",
    "@ray.remote\n",
    "def stage8to10():\n",
    "    tic = time.perf_counter()\n",
    "    print(\"* Stage 8: Loading the frozen model from file\")\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        with tf.io.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "            serialized_graph = fid.read()\n",
    "            graph_def.ParseFromString(serialized_graph)\n",
    "            tf.import_graph_def(graph_def, name='')\n",
    "    toc = time.perf_counter()\n",
    "    print(\"Stage 8 completed in\", round(toc - tic, 2), \"seconds\")\n",
    "    \n",
    "    # =====================\n",
    "    # Running the inference\n",
    "    # =====================\n",
    "    tic = time.perf_counter()\n",
    "    print(\"* Stage 9: Running the inference\")\n",
    "    IMAGE_NP_KEY = 'image_np'\n",
    "    RESULTS_KEY = 'results'\n",
    "    \n",
    "    file_result_dict = {}\n",
    "    \n",
    "    for filename in TEST_IMAGES:\n",
    "        image_np = load_image_into_numpy_array(Image.open(filename))\n",
    "        \n",
    "        output_dict = run_inference(graph, image_np)\n",
    " \n",
    "        results = process_output(output_dict[DETECTION_CLASSES_KEY],\n",
    "                                 output_dict[DETECTION_SCORES_KEY],\n",
    "                                 output_dict[DETECTION_BOXES_KEY],\n",
    "                                 category_index)\n",
    "\n",
    "        file_result_dict[filename] = { IMAGE_NP_KEY: image_np, RESULTS_KEY: results }\n",
    "    \n",
    "    toc = time.perf_counter()\n",
    "    print(\"Stage 9 completed in\", round(toc - tic, 2), \"seconds\")\n",
    "    \n",
    "    # ===================\n",
    "    # Showing the results\n",
    "    # ===================\n",
    "    tic = time.perf_counter()\n",
    "    print(\"* Stage 10: Showing the results\")\n",
    "    for filename, img_results_dict in file_result_dict.items():\n",
    "        detected = []\n",
    "        for r in img_results_dict[RESULTS_KEY]:\n",
    "            if r.score >= .4:\n",
    "                 detected.append(str(r))\n",
    "                 #print(filename, \"Identified as\", str(r))\n",
    "        print(filename, \"Identified as\", ', '.join(detected))\n",
    "    toc = time.perf_counter()\n",
    "    print(\"Stage 10 completed in\", round(toc - tic, 2), \"seconds\")\n",
    "    \n",
    "stage8to10.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 4.65 seconds\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m * Stage 8: Loading the frozen model from file\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m Stage 8 completed in 8.23 seconds\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m * Stage 9: Running the inference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:07.210112: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:07.210146: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:07.210166: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mgmt01): /proc/driver/nvidia/version does not exist\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:07.210769: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:07.852431: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:15.813019: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:56:45.019034: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:57:06.914805: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:57:33.637301: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:57:56.758658: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:58:22.418010: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m 2022-07-27 02:58:46.291956: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:690] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -3091 } dim { size: -3092 } dim { size: -3093 } dim { size: 1088 } } } inputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -108 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 17 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3000 num_cores: 4 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -108 } dim { size: 17 } dim { size: 17 } dim { size: 1088 } } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m Stage 9 completed in 175.69 seconds\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m * Stage 10: Showing the results\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/dog.jpg Identified as Dog (99%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/girl.jpg Identified as Human face (96%), Girl (90%), Drink (80%), Clothing (78%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/pets.jpg Identified as Dog (99%), Cat (95%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/man.jpg Identified as Human face (93%), Clothing (74%), Man (51%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/man2.jpg Identified as Human face (97%), Clothing (87%), Man (50%), Person (45%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/man3.jpg Identified as Man (74%), Person (44%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m images/cat.jpg Identified as Cat (99%)\n",
      "\u001b[2m\u001b[36m(stage8to10 pid=800765)\u001b[0m Stage 10 completed in 0.0 seconds\n"
     ]
    }
   ],
   "source": [
    "# Total execution time\n",
    "end_time = time.perf_counter()\n",
    "print(\"Total execution time:\", round(end_time - start_time, 2), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
